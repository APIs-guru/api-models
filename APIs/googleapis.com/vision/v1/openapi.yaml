openapi: 3.0.0
servers:
  - url: 'https://vision.googleapis.com/'
info:
  contact:
    name: Google
    url: 'https://google.com'
  description: 'Integrates Google Vision features, including image labeling, face, logo, and landmark detection, optical character recognition (OCR), and detection of explicit content, into applications.'
  license:
    name: Creative Commons Attribution 3.0
    url: 'http://creativecommons.org/licenses/by/3.0/'
  termsOfService: 'https://developers.google.com/terms/'
  title: Google Cloud Vision
  version: v1
  x-apiClientRegistration:
    url: 'https://console.developers.google.com'
  x-logo:
    url: 'https://www.google.com/images/branding/googlelogo/2x/googlelogo_color_272x92dp.png'
  x-origin:
    - converter:
        url: 'https://github.com/lucybot/api-spec-converter'
        version: 2.0.1
      format: google
      url: 'https://vision.googleapis.com/$discovery/rest?version=v1'
      version: v1
  x-preferred: true
  x-providerName: googleapis.com
  x-serviceName: vision
externalDocs:
  url: 'https://cloud.google.com/vision/'
tags:
  - name: images
paths:
  '/v1/images:annotate':
    parameters:
      - $ref: '#/components/parameters/upload_protocol'
      - $ref: '#/components/parameters/prettyPrint'
      - $ref: '#/components/parameters/uploadType'
      - $ref: '#/components/parameters/fields'
      - $ref: '#/components/parameters/callback'
      - $ref: '#/components/parameters/_.xgafv'
      - $ref: '#/components/parameters/alt'
      - $ref: '#/components/parameters/key'
      - $ref: '#/components/parameters/access_token'
      - $ref: '#/components/parameters/quotaUser'
      - $ref: '#/components/parameters/pp'
      - $ref: '#/components/parameters/bearer_token'
      - $ref: '#/components/parameters/oauth_token'
    post:
      description: Run image detection and annotation for a batch of images.
      operationId: vision.images.annotate
      responses:
        '200':
          description: Successful response
          content:
            '*/*':
              schema:
                $ref: '#/components/schemas/BatchAnnotateImagesResponse'
      security:
        - Oauth2:
            - 'https://www.googleapis.com/auth/cloud-platform'
          Oauth2c:
            - 'https://www.googleapis.com/auth/cloud-platform'
        - Oauth2:
            - 'https://www.googleapis.com/auth/cloud-vision'
          Oauth2c:
            - 'https://www.googleapis.com/auth/cloud-vision'
      tags:
        - images
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/BatchAnnotateImagesRequest'
components:
  schemas:
    AnnotateImageRequest:
      description: |-
        Request for performing Google Cloud Vision API tasks over a user-provided
        image, with user-requested features.
      properties:
        features:
          description: Requested features.
          items:
            $ref: '#/components/schemas/Feature'
          type: array
        image:
          $ref: '#/components/schemas/Image'
        imageContext:
          $ref: '#/components/schemas/ImageContext'
      type: object
    AnnotateImageResponse:
      description: Response to an image annotation request.
      properties:
        cropHintsAnnotation:
          $ref: '#/components/schemas/CropHintsAnnotation'
        error:
          $ref: '#/components/schemas/Status'
        faceAnnotations:
          description: 'If present, face detection has completed successfully.'
          items:
            $ref: '#/components/schemas/FaceAnnotation'
          type: array
        fullTextAnnotation:
          $ref: '#/components/schemas/TextAnnotation'
        imagePropertiesAnnotation:
          $ref: '#/components/schemas/ImageProperties'
        labelAnnotations:
          description: 'If present, label detection has completed successfully.'
          items:
            $ref: '#/components/schemas/EntityAnnotation'
          type: array
        landmarkAnnotations:
          description: 'If present, landmark detection has completed successfully.'
          items:
            $ref: '#/components/schemas/EntityAnnotation'
          type: array
        logoAnnotations:
          description: 'If present, logo detection has completed successfully.'
          items:
            $ref: '#/components/schemas/EntityAnnotation'
          type: array
        safeSearchAnnotation:
          $ref: '#/components/schemas/SafeSearchAnnotation'
        textAnnotations:
          description: 'If present, text (OCR) detection has completed successfully.'
          items:
            $ref: '#/components/schemas/EntityAnnotation'
          type: array
        webDetection:
          $ref: '#/components/schemas/WebDetection'
      type: object
    BatchAnnotateImagesRequest:
      description: Multiple image annotation requests are batched into a single service call.
      properties:
        requests:
          description: Individual image annotation requests for this batch.
          items:
            $ref: '#/components/schemas/AnnotateImageRequest'
          type: array
      type: object
    BatchAnnotateImagesResponse:
      description: Response to a batch image annotation request.
      properties:
        responses:
          description: Individual responses to image annotation requests within the batch.
          items:
            $ref: '#/components/schemas/AnnotateImageResponse'
          type: array
      type: object
    Block:
      description: Logical element on the page.
      properties:
        blockType:
          description: 'Detected block type (text, image etc) for this block.'
          enum:
            - UNKNOWN
            - TEXT
            - TABLE
            - PICTURE
            - RULER
            - BARCODE
          type: string
        boundingBox:
          $ref: '#/components/schemas/BoundingPoly'
        paragraphs:
          description: List of paragraphs in this block (if this blocks is of type text).
          items:
            $ref: '#/components/schemas/Paragraph'
          type: array
        property:
          $ref: '#/components/schemas/TextProperty'
      type: object
    BoundingPoly:
      description: A bounding polygon for the detected image annotation.
      properties:
        vertices:
          description: The bounding polygon vertices.
          items:
            $ref: '#/components/schemas/Vertex'
          type: array
      type: object
    Color:
      description: |-
        Represents a color in the RGBA color space. This representation is designed
        for simplicity of conversion to/from color representations in various
        languages over compactness; for example, the fields of this representation
        can be trivially provided to the constructor of "java.awt.Color" in Java; it
        can also be trivially provided to UIColor's "+colorWithRed:green:blue:alpha"
        method in iOS; and, with just a little work, it can be easily formatted into
        a CSS "rgba()" string in JavaScript, as well. Here are some examples:

        Example (Java):

             import com.google.type.Color;

             // ...
             public static java.awt.Color fromProto(Color protocolor) {
               float alpha = protocolor.hasAlpha()
                   ? protocolor.getAlpha().getValue()
                   : 1.0;

               return new java.awt.Color(
                   protocolor.getRed(),
                   protocolor.getGreen(),
                   protocolor.getBlue(),
                   alpha);
             }

             public static Color toProto(java.awt.Color color) {
               float red = (float) color.getRed();
               float green = (float) color.getGreen();
               float blue = (float) color.getBlue();
               float denominator = 255.0;
               Color.Builder resultBuilder =
                   Color
                       .newBuilder()
                       .setRed(red / denominator)
                       .setGreen(green / denominator)
                       .setBlue(blue / denominator);
               int alpha = color.getAlpha();
               if (alpha != 255) {
                 result.setAlpha(
                     FloatValue
                         .newBuilder()
                         .setValue(((float) alpha) / denominator)
                         .build());
               }
               return resultBuilder.build();
             }
             // ...

        Example (iOS / Obj-C):

             // ...
             static UIColor* fromProto(Color* protocolor) {
                float red = [protocolor red];
                float green = [protocolor green];
                float blue = [protocolor blue];
                FloatValue* alpha_wrapper = [protocolor alpha];
                float alpha = 1.0;
                if (alpha_wrapper != nil) {
                  alpha = [alpha_wrapper value];
                }
                return [UIColor colorWithRed:red green:green blue:blue alpha:alpha];
             }

             static Color* toProto(UIColor* color) {
                 CGFloat red, green, blue, alpha;
                 if (![color getRed:&red green:&green blue:&blue alpha:&alpha]) {
                   return nil;
                 }
                 Color* result = [Color alloc] init];
                 [result setRed:red];
                 [result setGreen:green];
                 [result setBlue:blue];
                 if (alpha <= 0.9999) {
                   [result setAlpha:floatWrapperWithValue(alpha)];
                 }
                 [result autorelease];
                 return result;
            }
            // ...

         Example (JavaScript):

            // ...

            var protoToCssColor = function(rgb_color) {
               var redFrac = rgb_color.red || 0.0;
               var greenFrac = rgb_color.green || 0.0;
               var blueFrac = rgb_color.blue || 0.0;
               var red = Math.floor(redFrac * 255);
               var green = Math.floor(greenFrac * 255);
               var blue = Math.floor(blueFrac * 255);

               if (!('alpha' in rgb_color)) {
                  return rgbToCssColor_(red, green, blue);
               }

               var alphaFrac = rgb_color.alpha.value || 0.0;
               var rgbParams = [red, green, blue].join(',');
               return ['rgba(', rgbParams, ',', alphaFrac, ')'].join('');
            };

            var rgbToCssColor_ = function(red, green, blue) {
              var rgbNumber = new Number((red << 16) | (green << 8) | blue);
              var hexString = rgbNumber.toString(16);
              var missingZeros = 6 - hexString.length;
              var resultBuilder = ['#'];
              for (var i = 0; i < missingZeros; i++) {
                 resultBuilder.push('0');
              }
              resultBuilder.push(hexString);
              return resultBuilder.join('');
            };

            // ...
      properties:
        alpha:
          description: |-
            The fraction of this color that should be applied to the pixel. That is,
            the final pixel color is defined by the equation:

              pixel color = alpha * (this color) + (1.0 - alpha) * (background color)

            This means that a value of 1.0 corresponds to a solid color, whereas
            a value of 0.0 corresponds to a completely transparent color. This
            uses a wrapper message rather than a simple float scalar so that it is
            possible to distinguish between a default value and the value being unset.
            If omitted, this color object is to be rendered as a solid color
            (as if the alpha value had been explicitly given with a value of 1.0).
          format: float
          type: number
        blue:
          description: 'The amount of blue in the color as a value in the interval [0, 1].'
          format: float
          type: number
        green:
          description: 'The amount of green in the color as a value in the interval [0, 1].'
          format: float
          type: number
        red:
          description: 'The amount of red in the color as a value in the interval [0, 1].'
          format: float
          type: number
      type: object
    ColorInfo:
      description: |-
        Color information consists of RGB channels, score, and the fraction of
        the image that the color occupies in the image.
      properties:
        color:
          $ref: '#/components/schemas/Color'
        pixelFraction:
          description: |-
            The fraction of pixels the color occupies in the image.
            Value in range [0, 1].
          format: float
          type: number
        score:
          description: 'Image-specific score for this color. Value in range [0, 1].'
          format: float
          type: number
      type: object
    CropHint:
      description: Single crop hint that is used to generate a new crop when serving an image.
      properties:
        boundingPoly:
          $ref: '#/components/schemas/BoundingPoly'
        confidence:
          description: 'Confidence of this being a salient region.  Range [0, 1].'
          format: float
          type: number
        importanceFraction:
          description: |-
            Fraction of importance of this salient region with respect to the original
            image.
          format: float
          type: number
      type: object
    CropHintsAnnotation:
      description: Set of crop hints that are used to generate new crops when serving images.
      properties:
        cropHints:
          description: Crop hint results.
          items:
            $ref: '#/components/schemas/CropHint'
          type: array
      type: object
    CropHintsParams:
      description: Parameters for crop hints annotation request.
      properties:
        aspectRatios:
          description: |-
            Aspect ratios in floats, representing the ratio of the width to the height
            of the image. For example, if the desired aspect ratio is 4/3, the
            corresponding float value should be 1.33333.  If not specified, the
            best possible crop is returned. The number of provided aspect ratios is
            limited to a maximum of 16; any aspect ratios provided after the 16th are
            ignored.
          items:
            format: float
            type: number
          type: array
      type: object
    DetectedBreak:
      description: Detected start or end of a structural component.
      properties:
        isPrefix:
          description: True if break prepends the element.
          type: boolean
        type:
          description: Detected break type.
          enum:
            - UNKNOWN
            - SPACE
            - SURE_SPACE
            - EOL_SURE_SPACE
            - HYPHEN
            - LINE_BREAK
          type: string
      type: object
    DetectedLanguage:
      description: Detected language for a structural component.
      properties:
        confidence:
          description: 'Confidence of detected language. Range [0, 1].'
          format: float
          type: number
        languageCode:
          description: |-
            The BCP-47 language code, such as "en-US" or "sr-Latn". For more
            information, see
            http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
          type: string
      type: object
    DominantColorsAnnotation:
      description: Set of dominant colors and their corresponding scores.
      properties:
        colors:
          description: RGB color values with their score and pixel fraction.
          items:
            $ref: '#/components/schemas/ColorInfo'
          type: array
      type: object
    EntityAnnotation:
      description: Set of detected entity features.
      properties:
        boundingPoly:
          $ref: '#/components/schemas/BoundingPoly'
        confidence:
          description: |-
            The accuracy of the entity detection in an image.
            For example, for an image in which the "Eiffel Tower" entity is detected,
            this field represents the confidence that there is a tower in the query
            image. Range [0, 1].
          format: float
          type: number
        description:
          description: 'Entity textual description, expressed in its `locale` language.'
          type: string
        locale:
          description: |-
            The language code for the locale in which the entity textual
            `description` is expressed.
          type: string
        locations:
          description: |-
            The location information for the detected entity. Multiple
            `LocationInfo` elements can be present because one location may
            indicate the location of the scene in the image, and another location
            may indicate the location of the place where the image was taken.
            Location information is usually present for landmarks.
          items:
            $ref: '#/components/schemas/LocationInfo'
          type: array
        mid:
          description: |-
            Opaque entity ID. Some IDs may be available in
            [Google Knowledge Graph Search API](https://developers.google.com/knowledge-graph/).
          type: string
        properties:
          description: |-
            Some entities may have optional user-supplied `Property` (name/value)
            fields, such a score or string that qualifies the entity.
          items:
            $ref: '#/components/schemas/Property'
          type: array
        score:
          description: 'Overall score of the result. Range [0, 1].'
          format: float
          type: number
        topicality:
          description: |-
            The relevancy of the ICA (Image Content Annotation) label to the
            image. For example, the relevancy of "tower" is likely higher to an image
            containing the detected "Eiffel Tower" than to an image containing a
            detected distant towering building, even though the confidence that
            there is a tower in each image may be the same. Range [0, 1].
          format: float
          type: number
      type: object
    FaceAnnotation:
      description: A face annotation object contains the results of face detection.
      properties:
        angerLikelihood:
          description: Anger likelihood.
          enum:
            - UNKNOWN
            - VERY_UNLIKELY
            - UNLIKELY
            - POSSIBLE
            - LIKELY
            - VERY_LIKELY
          type: string
        blurredLikelihood:
          description: Blurred likelihood.
          enum:
            - UNKNOWN
            - VERY_UNLIKELY
            - UNLIKELY
            - POSSIBLE
            - LIKELY
            - VERY_LIKELY
          type: string
        boundingPoly:
          $ref: '#/components/schemas/BoundingPoly'
        detectionConfidence:
          description: 'Detection confidence. Range [0, 1].'
          format: float
          type: number
        fdBoundingPoly:
          $ref: '#/components/schemas/BoundingPoly'
        headwearLikelihood:
          description: Headwear likelihood.
          enum:
            - UNKNOWN
            - VERY_UNLIKELY
            - UNLIKELY
            - POSSIBLE
            - LIKELY
            - VERY_LIKELY
          type: string
        joyLikelihood:
          description: Joy likelihood.
          enum:
            - UNKNOWN
            - VERY_UNLIKELY
            - UNLIKELY
            - POSSIBLE
            - LIKELY
            - VERY_LIKELY
          type: string
        landmarkingConfidence:
          description: 'Face landmarking confidence. Range [0, 1].'
          format: float
          type: number
        landmarks:
          description: Detected face landmarks.
          items:
            $ref: '#/components/schemas/Landmark'
          type: array
        panAngle:
          description: |-
            Yaw angle, which indicates the leftward/rightward angle that the face is
            pointing relative to the vertical plane perpendicular to the image. Range
            [-180,180].
          format: float
          type: number
        rollAngle:
          description: |-
            Roll angle, which indicates the amount of clockwise/anti-clockwise rotation
            of the face relative to the image vertical about the axis perpendicular to
            the face. Range [-180,180].
          format: float
          type: number
        sorrowLikelihood:
          description: Sorrow likelihood.
          enum:
            - UNKNOWN
            - VERY_UNLIKELY
            - UNLIKELY
            - POSSIBLE
            - LIKELY
            - VERY_LIKELY
          type: string
        surpriseLikelihood:
          description: Surprise likelihood.
          enum:
            - UNKNOWN
            - VERY_UNLIKELY
            - UNLIKELY
            - POSSIBLE
            - LIKELY
            - VERY_LIKELY
          type: string
        tiltAngle:
          description: |-
            Pitch angle, which indicates the upwards/downwards angle that the face is
            pointing relative to the image's horizontal plane. Range [-180,180].
          format: float
          type: number
        underExposedLikelihood:
          description: Under-exposed likelihood.
          enum:
            - UNKNOWN
            - VERY_UNLIKELY
            - UNLIKELY
            - POSSIBLE
            - LIKELY
            - VERY_LIKELY
          type: string
      type: object
    Feature:
      description: |-
        Users describe the type of Google Cloud Vision API tasks to perform over
        images by using *Feature*s. Each Feature indicates a type of image
        detection task to perform. Features encode the Cloud Vision API
        vertical to operate on and the number of top-scoring results to return.
      properties:
        maxResults:
          description: Maximum number of results of this type.
          format: int32
          type: integer
        type:
          description: The feature type.
          enum:
            - TYPE_UNSPECIFIED
            - FACE_DETECTION
            - LANDMARK_DETECTION
            - LOGO_DETECTION
            - LABEL_DETECTION
            - TEXT_DETECTION
            - DOCUMENT_TEXT_DETECTION
            - SAFE_SEARCH_DETECTION
            - IMAGE_PROPERTIES
            - CROP_HINTS
            - WEB_DETECTION
          type: string
      type: object
    Image:
      description: Client image to perform Google Cloud Vision API tasks over.
      properties:
        content:
          description: |-
            Image content, represented as a stream of bytes.
            Note: as with all `bytes` fields, protobuffers use a pure binary
            representation, whereas JSON representations use base64.
          format: byte
          type: string
        source:
          $ref: '#/components/schemas/ImageSource'
      type: object
    ImageContext:
      description: Image context and/or feature-specific parameters.
      properties:
        cropHintsParams:
          $ref: '#/components/schemas/CropHintsParams'
        languageHints:
          description: |-
            List of languages to use for TEXT_DETECTION. In most cases, an empty value
            yields the best results since it enables automatic language detection. For
            languages based on the Latin alphabet, setting `language_hints` is not
            needed. In rare cases, when the language of the text in the image is known,
            setting a hint will help get better results (although it will be a
            significant hindrance if the hint is wrong). Text detection returns an
            error if one or more of the specified languages is not one of the
            [supported languages](/vision/docs/languages).
          items:
            type: string
          type: array
        latLongRect:
          $ref: '#/components/schemas/LatLongRect'
      type: object
    ImageProperties:
      description: 'Stores image properties, such as dominant colors.'
      properties:
        dominantColors:
          $ref: '#/components/schemas/DominantColorsAnnotation'
      type: object
    ImageSource:
      description: External image source (Google Cloud Storage image location).
      properties:
        gcsImageUri:
          description: |-
            NOTE: For new code `image_uri` below is preferred.
            Google Cloud Storage image URI, which must be in the following form:
            `gs://bucket_name/object_name` (for details, see
            [Google Cloud Storage Request
            URIs](https://cloud.google.com/storage/docs/reference-uris)).
            NOTE: Cloud Storage object versioning is not supported.
          type: string
        imageUri:
          description: |-
            Image URI which supports:
            1) Google Cloud Storage image URI, which must be in the following form:
            `gs://bucket_name/object_name` (for details, see
            [Google Cloud Storage Request
            URIs](https://cloud.google.com/storage/docs/reference-uris)).
            NOTE: Cloud Storage object versioning is not supported.
            2) Publicly accessible image HTTP/HTTPS URL.
            This is preferred over the legacy `gcs_image_uri` above. When both
            `gcs_image_uri` and `image_uri` are specified, `image_uri` takes
            precedence.
          type: string
      type: object
    Landmark:
      description: |-
        A face-specific landmark (for example, a face feature).
        Landmark positions may fall outside the bounds of the image
        if the face is near one or more edges of the image.
        Therefore it is NOT guaranteed that `0 <= x < width` or
        `0 <= y < height`.
      properties:
        position:
          $ref: '#/components/schemas/Position'
        type:
          description: Face landmark type.
          enum:
            - UNKNOWN_LANDMARK
            - LEFT_EYE
            - RIGHT_EYE
            - LEFT_OF_LEFT_EYEBROW
            - RIGHT_OF_LEFT_EYEBROW
            - LEFT_OF_RIGHT_EYEBROW
            - RIGHT_OF_RIGHT_EYEBROW
            - MIDPOINT_BETWEEN_EYES
            - NOSE_TIP
            - UPPER_LIP
            - LOWER_LIP
            - MOUTH_LEFT
            - MOUTH_RIGHT
            - MOUTH_CENTER
            - NOSE_BOTTOM_RIGHT
            - NOSE_BOTTOM_LEFT
            - NOSE_BOTTOM_CENTER
            - LEFT_EYE_TOP_BOUNDARY
            - LEFT_EYE_RIGHT_CORNER
            - LEFT_EYE_BOTTOM_BOUNDARY
            - LEFT_EYE_LEFT_CORNER
            - RIGHT_EYE_TOP_BOUNDARY
            - RIGHT_EYE_RIGHT_CORNER
            - RIGHT_EYE_BOTTOM_BOUNDARY
            - RIGHT_EYE_LEFT_CORNER
            - LEFT_EYEBROW_UPPER_MIDPOINT
            - RIGHT_EYEBROW_UPPER_MIDPOINT
            - LEFT_EAR_TRAGION
            - RIGHT_EAR_TRAGION
            - LEFT_EYE_PUPIL
            - RIGHT_EYE_PUPIL
            - FOREHEAD_GLABELLA
            - CHIN_GNATHION
            - CHIN_LEFT_GONION
            - CHIN_RIGHT_GONION
          type: string
      type: object
    LatLng:
      description: |-
        An object representing a latitude/longitude pair. This is expressed as a pair
        of doubles representing degrees latitude and degrees longitude. Unless
        specified otherwise, this must conform to the
        <a href="http://www.unoosa.org/pdf/icg/2012/template/WGS_84.pdf">WGS84
        standard</a>. Values must be within normalized ranges.

        Example of normalization code in Python:

            def NormalizeLongitude(longitude):
              """Wraps decimal degrees longitude to [-180.0, 180.0]."""
              q, r = divmod(longitude, 360.0)
              if r > 180.0 or (r == 180.0 and q <= -1.0):
                return r - 360.0
              return r

            def NormalizeLatLng(latitude, longitude):
              """Wraps decimal degrees latitude and longitude to
              [-90.0, 90.0] and [-180.0, 180.0], respectively."""
              r = latitude % 360.0
              if r <= 90.0:
                return r, NormalizeLongitude(longitude)
              elif r >= 270.0:
                return r - 360, NormalizeLongitude(longitude)
              else:
                return 180 - r, NormalizeLongitude(longitude + 180.0)

            assert 180.0 == NormalizeLongitude(180.0)
            assert -180.0 == NormalizeLongitude(-180.0)
            assert -179.0 == NormalizeLongitude(181.0)
            assert (0.0, 0.0) == NormalizeLatLng(360.0, 0.0)
            assert (0.0, 0.0) == NormalizeLatLng(-360.0, 0.0)
            assert (85.0, 180.0) == NormalizeLatLng(95.0, 0.0)
            assert (-85.0, -170.0) == NormalizeLatLng(-95.0, 10.0)
            assert (90.0, 10.0) == NormalizeLatLng(90.0, 10.0)
            assert (-90.0, -10.0) == NormalizeLatLng(-90.0, -10.0)
            assert (0.0, -170.0) == NormalizeLatLng(-180.0, 10.0)
            assert (0.0, -170.0) == NormalizeLatLng(180.0, 10.0)
            assert (-90.0, 10.0) == NormalizeLatLng(270.0, 10.0)
            assert (90.0, 10.0) == NormalizeLatLng(-270.0, 10.0)
      properties:
        latitude:
          description: 'The latitude in degrees. It must be in the range [-90.0, +90.0].'
          format: double
          type: number
        longitude:
          description: 'The longitude in degrees. It must be in the range [-180.0, +180.0].'
          format: double
          type: number
      type: object
    LatLongRect:
      description: Rectangle determined by min and max `LatLng` pairs.
      properties:
        maxLatLng:
          $ref: '#/components/schemas/LatLng'
        minLatLng:
          $ref: '#/components/schemas/LatLng'
      type: object
    LocationInfo:
      description: Detected entity location information.
      properties:
        latLng:
          $ref: '#/components/schemas/LatLng'
      type: object
    Page:
      description: Detected page from OCR.
      properties:
        blocks:
          description: 'List of blocks of text, images etc on this page.'
          items:
            $ref: '#/components/schemas/Block'
          type: array
        height:
          description: Page height in pixels.
          format: int32
          type: integer
        property:
          $ref: '#/components/schemas/TextProperty'
        width:
          description: Page width in pixels.
          format: int32
          type: integer
      type: object
    Paragraph:
      description: Structural unit of text representing a number of words in certain order.
      properties:
        boundingBox:
          $ref: '#/components/schemas/BoundingPoly'
        property:
          $ref: '#/components/schemas/TextProperty'
        words:
          description: List of words in this paragraph.
          items:
            $ref: '#/components/schemas/Word'
          type: array
      type: object
    Position:
      description: |-
        A 3D position in the image, used primarily for Face detection landmarks.
        A valid Position must have both x and y coordinates.
        The position coordinates are in the same scale as the original image.
      properties:
        x:
          description: X coordinate.
          format: float
          type: number
        'y':
          description: Y coordinate.
          format: float
          type: number
        z:
          description: Z coordinate (or depth).
          format: float
          type: number
      type: object
    Property:
      description: A `Property` consists of a user-supplied name/value pair.
      properties:
        name:
          description: Name of the property.
          type: string
        uint64Value:
          description: Value of numeric properties.
          format: uint64
          type: string
        value:
          description: Value of the property.
          type: string
      type: object
    SafeSearchAnnotation:
      description: |-
        Set of features pertaining to the image, computed by computer vision
        methods over safe-search verticals (for example, adult, spoof, medical,
        violence).
      properties:
        adult:
          description: Represents the adult content likelihood for the image.
          enum:
            - UNKNOWN
            - VERY_UNLIKELY
            - UNLIKELY
            - POSSIBLE
            - LIKELY
            - VERY_LIKELY
          type: string
        medical:
          description: Likelihood that this is a medical image.
          enum:
            - UNKNOWN
            - VERY_UNLIKELY
            - UNLIKELY
            - POSSIBLE
            - LIKELY
            - VERY_LIKELY
          type: string
        spoof:
          description: |-
            Spoof likelihood. The likelihood that an modification
            was made to the image's canonical version to make it appear
            funny or offensive.
          enum:
            - UNKNOWN
            - VERY_UNLIKELY
            - UNLIKELY
            - POSSIBLE
            - LIKELY
            - VERY_LIKELY
          type: string
        violence:
          description: Violence likelihood.
          enum:
            - UNKNOWN
            - VERY_UNLIKELY
            - UNLIKELY
            - POSSIBLE
            - LIKELY
            - VERY_LIKELY
          type: string
      type: object
    Status:
      description: |-
        The `Status` type defines a logical error model that is suitable for different
        programming environments, including REST APIs and RPC APIs. It is used by
        [gRPC](https://github.com/grpc). The error model is designed to be:

        - Simple to use and understand for most users
        - Flexible enough to meet unexpected needs

        # Overview

        The `Status` message contains three pieces of data: error code, error message,
        and error details. The error code should be an enum value of
        google.rpc.Code, but it may accept additional error codes if needed.  The
        error message should be a developer-facing English message that helps
        developers *understand* and *resolve* the error. If a localized user-facing
        error message is needed, put the localized message in the error details or
        localize it in the client. The optional error details may contain arbitrary
        information about the error. There is a predefined set of error detail types
        in the package `google.rpc` that can be used for common error conditions.

        # Language mapping

        The `Status` message is the logical representation of the error model, but it
        is not necessarily the actual wire format. When the `Status` message is
        exposed in different client libraries and different wire protocols, it can be
        mapped differently. For example, it will likely be mapped to some exceptions
        in Java, but more likely mapped to some error codes in C.

        # Other uses

        The error model and the `Status` message can be used in a variety of
        environments, either with or without APIs, to provide a
        consistent developer experience across different environments.

        Example uses of this error model include:

        - Partial errors. If a service needs to return partial errors to the client,
            it may embed the `Status` in the normal response to indicate the partial
            errors.

        - Workflow errors. A typical workflow has multiple steps. Each step may
            have a `Status` message for error reporting.

        - Batch operations. If a client uses batch request and batch response, the
            `Status` message should be used directly inside batch response, one for
            each error sub-response.

        - Asynchronous operations. If an API call embeds asynchronous operation
            results in its response, the status of those operations should be
            represented directly using the `Status` message.

        - Logging. If some API errors are stored in logs, the message `Status` could
            be used directly after any stripping needed for security/privacy reasons.
      properties:
        code:
          description: 'The status code, which should be an enum value of google.rpc.Code.'
          format: int32
          type: integer
        details:
          description: |-
            A list of messages that carry the error details.  There will be a
            common set of message types for APIs to use.
          items:
            additionalProperties:
              description: Properties of the object. Contains field @type with type URL.
            type: object
          type: array
        message:
          description: |-
            A developer-facing error message, which should be in English. Any
            user-facing error message should be localized and sent in the
            google.rpc.Status.details field, or localized by the client.
          type: string
      type: object
    Symbol:
      description: A single symbol representation.
      properties:
        boundingBox:
          $ref: '#/components/schemas/BoundingPoly'
        property:
          $ref: '#/components/schemas/TextProperty'
        text:
          description: The actual UTF-8 representation of the symbol.
          type: string
      type: object
    TextAnnotation:
      description: |-
        TextAnnotation contains a structured representation of OCR extracted text.
        The hierarchy of an OCR extracted text structure is like this:
            TextAnnotation -> Page -> Block -> Paragraph -> Word -> Symbol
        Each structural component, starting from Page, may further have their own
        properties. Properties describe detected languages, breaks etc.. Please
        refer to the google.cloud.vision.v1.TextAnnotation.TextProperty message
        definition below for more detail.
      properties:
        pages:
          description: List of pages detected by OCR.
          items:
            $ref: '#/components/schemas/Page'
          type: array
        text:
          description: UTF-8 text detected on the pages.
          type: string
      type: object
    TextProperty:
      description: Additional information detected on the structural component.
      properties:
        detectedBreak:
          $ref: '#/components/schemas/DetectedBreak'
        detectedLanguages:
          description: A list of detected languages together with confidence.
          items:
            $ref: '#/components/schemas/DetectedLanguage'
          type: array
      type: object
    Vertex:
      description: |-
        A vertex represents a 2D point in the image.
        NOTE: the vertex coordinates are in the same scale as the original image.
      properties:
        x:
          description: X coordinate.
          format: int32
          type: integer
        'y':
          description: Y coordinate.
          format: int32
          type: integer
      type: object
    WebDetection:
      description: Relevant information for the image from the Internet.
      properties:
        fullMatchingImages:
          description: |-
            Fully matching images from the Internet.
            Can include resized copies of the query image.
          items:
            $ref: '#/components/schemas/WebImage'
          type: array
        pagesWithMatchingImages:
          description: Web pages containing the matching images from the Internet.
          items:
            $ref: '#/components/schemas/WebPage'
          type: array
        partialMatchingImages:
          description: |-
            Partial matching images from the Internet.
            Those images are similar enough to share some key-point features. For
            example an original image will likely have partial matching for its crops.
          items:
            $ref: '#/components/schemas/WebImage'
          type: array
        visuallySimilarImages:
          description: The visually similar image results.
          items:
            $ref: '#/components/schemas/WebImage'
          type: array
        webEntities:
          description: Deduced entities from similar images on the Internet.
          items:
            $ref: '#/components/schemas/WebEntity'
          type: array
      type: object
    WebEntity:
      description: Entity deduced from similar images on the Internet.
      properties:
        description:
          description: 'Canonical description of the entity, in English.'
          type: string
        entityId:
          description: Opaque entity ID.
          type: string
        score:
          description: |-
            Overall relevancy score for the entity.
            Not normalized and not comparable across different image queries.
          format: float
          type: number
      type: object
    WebImage:
      description: Metadata for online images.
      properties:
        score:
          description: |-
            Overall relevancy score for the image.
            Not normalized and not comparable across different image queries.
          format: float
          type: number
        url:
          description: The result image URL.
          type: string
      type: object
    WebPage:
      description: Metadata for web pages.
      properties:
        score:
          description: |-
            Overall relevancy score for the web page.
            Not normalized and not comparable across different image queries.
          format: float
          type: number
        url:
          description: The result web page URL.
          type: string
      type: object
    Word:
      description: A word representation.
      properties:
        boundingBox:
          $ref: '#/components/schemas/BoundingPoly'
        property:
          $ref: '#/components/schemas/TextProperty'
        symbols:
          description: |-
            List of symbols in the word.
            The order of the symbols follows the natural reading order.
          items:
            $ref: '#/components/schemas/Symbol'
          type: array
      type: object
  parameters:
    access_token:
      description: OAuth access token.
      in: query
      name: access_token
      schema:
        type: string
    alt:
      description: Data format for response.
      in: query
      name: alt
      schema:
        type: string
        enum:
          - json
          - media
          - proto
        default: json
    bearer_token:
      description: OAuth bearer token.
      in: query
      name: bearer_token
      schema:
        type: string
    callback:
      description: JSONP
      in: query
      name: callback
      schema:
        type: string
    fields:
      description: Selector specifying which fields to include in a partial response.
      in: query
      name: fields
      schema:
        type: string
    key:
      description: 'API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token.'
      in: query
      name: key
      schema:
        type: string
    oauth_token:
      description: OAuth 2.0 token for the current user.
      in: query
      name: oauth_token
      schema:
        type: string
    pp:
      description: Pretty-print response.
      in: query
      name: pp
      schema:
        type: boolean
        default: true
    prettyPrint:
      description: Returns response with indentations and line breaks.
      in: query
      name: prettyPrint
      schema:
        type: boolean
        default: true
    quotaUser:
      description: 'Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters.'
      in: query
      name: quotaUser
      schema:
        type: string
    uploadType:
      description: 'Legacy upload protocol for media (e.g. "media", "multipart").'
      in: query
      name: uploadType
      schema:
        type: string
    upload_protocol:
      description: 'Upload protocol for media (e.g. "raw", "multipart").'
      in: query
      name: upload_protocol
      schema:
        type: string
    _.xgafv:
      description: V1 error format.
      in: query
      name: $.xgafv
      schema:
        type: string
        enum:
          - '1'
          - '2'
  securitySchemes:
    Oauth2:
      description: Oauth 2.0 implicit authentication
      type: oauth2
      flows:
        implicit:
          authorizationUrl: 'https://accounts.google.com/o/oauth2/auth'
          scopes:
            'https://www.googleapis.com/auth/cloud-platform': View and manage your data across Google Cloud Platform services
            'https://www.googleapis.com/auth/cloud-vision': Apply machine learning models to understand and label images
    Oauth2c:
      description: Oauth 2.0 accessCode authentication
      type: oauth2
      flows:
        authorizationCode:
          authorizationUrl: 'https://accounts.google.com/o/oauth2/auth'
          tokenUrl: 'https://accounts.google.com/o/oauth2/token'
          scopes:
            'https://www.googleapis.com/auth/cloud-platform': View and manage your data across Google Cloud Platform services
            'https://www.googleapis.com/auth/cloud-vision': Apply machine learning models to understand and label images
